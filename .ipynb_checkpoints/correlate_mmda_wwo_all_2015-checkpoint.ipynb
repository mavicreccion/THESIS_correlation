{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get weather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_dataset = pd.read_csv('weather_wwo_manila_2015.csv', skipinitialspace=True, encoding='cp1252')\n",
    "cols = [\"tempC\", \"windspeedKmph\", \"cond\", \"precipMM\", \"humidity\", \"visibility\", \"pressure\", \"cloudcover\", \"heatIndexC\", \"dewPointC\", \"windChillC\", \"windGustKmph\", \"feelsLikeC\"]\n",
    "date_dataset = weather_dataset[\"dt\"]\n",
    "weather_dataset = weather_dataset[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlate traffic and weather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roads = [\"A. Maceda\", \"Anda Circle\", \"Antipolo\", \"Bluementritt\", \"Buendia\", \"Edsa Extension\", \"Finance Road\", \"Gov. Forbes - Lacson\", \"Lerma\", \"Magsaysay Ave\", \"P.Noval\", \"Pablo Ocampo\", \"Pedro Gil\", \"Quezon Ave.\", \"Quirino\", \"Rajah Sulayman\", \"Taft Ave.\", \"U.N. Avenue\", \"Vicente Cruz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for road in roads:\n",
    "    traffic_dataset = pd.read_csv('mmda_2015_transformed/mmda_' + road + '_2015_transformed.csv', skipinitialspace=True, encoding='cp1252')\n",
    "    traffic_dataset = traffic_dataset[['statusN', 'statusS']]\n",
    "    \n",
    "    # merge traffic and weather dataset\n",
    "    dataset = pd.concat([traffic_dataset, weather_dataset], axis=1, join='inner')\n",
    "    \n",
    "    # correlate\n",
    "    corr = dataset.corr(method='spearman')\n",
    "    corr.to_csv('corr_mmda_wwo_2015/corr_results_mmda_wwo_' + road + '_2015.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlate traffic and weather dataset wth lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roads = [\"A. Maceda\", \"Anda Circle\", \"Antipolo\", \"Bluementritt\", \"Buendia\", \"Edsa Extension\", \"Finance Road\", \"Gov. Forbes - Lacson\", \"Lerma\", \"Magsaysay Ave\", \"P.Noval\", \"Pablo Ocampo\", \"Pedro Gil\", \"Quezon Ave.\", \"Quirino\", \"Rajah Sulayman\", \"Taft Ave.\", \"U.N. Avenue\", \"Vicente Cruz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_lags = 8\n",
    "\n",
    "for road in roads:\n",
    "    traffic_dataset = pd.read_csv('mmda_2015_transformed/mmda_' + road + '_2015_transformed.csv', skipinitialspace=True, encoding='cp1252')\n",
    "    traffic_dataset = traffic_dataset[['statusN', 'statusS']]\n",
    "    \n",
    "    # merge traffic and weather dataset\n",
    "    dataset = pd.concat([traffic_dataset, weather_dataset], axis=1, join='inner')\n",
    "    \n",
    "    # make a copy\n",
    "    new_dataset = dataset.copy()\n",
    "    \n",
    "    for i in range(1, (total_lags+1)):\n",
    "        new_dataset.statusN = new_dataset.statusN.shift(-1)\n",
    "        new_dataset.statusS = new_dataset.statusS.shift(-1)\n",
    "        new_dataset = new_dataset[:(len(new_dataset)-1)]\n",
    "\n",
    "        corr = new_dataset.corr(method='spearman')\n",
    "        corr.to_csv('corr_mmda_wwo_2015_lags/corr_mmda_wwo_' + road + '_2015_lag_' + str(i) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1, (total_lags+1)):\n",
    "    \n",
    "    lag_dataset = []\n",
    "    \n",
    "    for road in roads:\n",
    "        dataset = pd.read_csv('corr_mmda_wwo_2015_lags/corr_mmda_wwo_' + road + '_2015_lag_' + str(i) + '.csv', skipinitialspace=True, encoding='cp1252')\n",
    "        dataset = dataset.loc[:, ~dataset.columns.str.contains('^Unnamed')]\n",
    "        dataset = dataset.loc[:1]\n",
    "        \n",
    "        lag_dataset.append(dataset)\n",
    "    \n",
    "    lag_dataset = pd.concat(lag_dataset)\n",
    "    lag_dataset.to_csv('corr_mmda_wwo_2015_lags/corr_mmda_wwo_2015_lag_' + str(i) + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlate traffic and weather with seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           1/1/2015 0:00\n",
       "1           1/1/2015 0:15\n",
       "2           1/1/2015 0:30\n",
       "3           1/1/2015 0:45\n",
       "4           1/1/2015 1:00\n",
       "5           1/1/2015 1:15\n",
       "6           1/1/2015 1:30\n",
       "7           1/1/2015 1:45\n",
       "8           1/1/2015 2:00\n",
       "9           1/1/2015 2:15\n",
       "10          1/1/2015 2:30\n",
       "11          1/1/2015 2:45\n",
       "12          1/1/2015 3:00\n",
       "13          1/1/2015 3:15\n",
       "14          1/1/2015 3:30\n",
       "15          1/1/2015 3:45\n",
       "16          1/1/2015 4:00\n",
       "17          1/1/2015 4:15\n",
       "18          1/1/2015 4:30\n",
       "19          1/1/2015 4:45\n",
       "20          1/1/2015 5:00\n",
       "21          1/1/2015 5:15\n",
       "22          1/1/2015 5:30\n",
       "23          1/1/2015 5:45\n",
       "24          1/1/2015 6:00\n",
       "25          1/1/2015 6:15\n",
       "26          1/1/2015 6:30\n",
       "27          1/1/2015 6:45\n",
       "28          1/1/2015 7:00\n",
       "29          1/1/2015 7:15\n",
       "               ...       \n",
       "35010    12/31/2015 16:30\n",
       "35011    12/31/2015 16:45\n",
       "35012    12/31/2015 17:00\n",
       "35013    12/31/2015 17:15\n",
       "35014    12/31/2015 17:30\n",
       "35015    12/31/2015 17:45\n",
       "35016    12/31/2015 18:00\n",
       "35017    12/31/2015 18:15\n",
       "35018    12/31/2015 18:30\n",
       "35019    12/31/2015 18:45\n",
       "35020    12/31/2015 19:00\n",
       "35021    12/31/2015 19:15\n",
       "35022    12/31/2015 19:30\n",
       "35023    12/31/2015 19:45\n",
       "35024    12/31/2015 20:00\n",
       "35025    12/31/2015 20:15\n",
       "35026    12/31/2015 20:30\n",
       "35027    12/31/2015 20:45\n",
       "35028    12/31/2015 21:00\n",
       "35029    12/31/2015 21:15\n",
       "35030    12/31/2015 21:30\n",
       "35031    12/31/2015 21:45\n",
       "35032    12/31/2015 22:00\n",
       "35033    12/31/2015 22:15\n",
       "35034    12/31/2015 22:30\n",
       "35035    12/31/2015 22:45\n",
       "35036    12/31/2015 23:00\n",
       "35037    12/31/2015 23:15\n",
       "35038    12/31/2015 23:30\n",
       "35039    12/31/2015 23:45\n",
       "Name: dt, Length: 35040, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
